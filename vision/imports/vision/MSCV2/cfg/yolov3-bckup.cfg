[net]
channels=3
input_dim=256
classes=12

# 0
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# +++ Downsample

# 1
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# 2
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=0
activation=leaky

# 3
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 4
[shortcut]
from=-3
activation=linear

# +++ Downsample

# 5
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

# 6
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

# 7
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 8
[shortcut]
from=-3
activation=linear

# 9
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

# 10
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 11
[shortcut]
from=-3
activation=linear

# Downsample

# 12
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

# 13
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 14
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 15
[shortcut]
from=-3
activation=linear

# 16
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 17
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 18
[shortcut]
from=-3
activation=linear

# 19
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 20
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 21
[shortcut]
from=-3
activation=linear

# 22
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 23
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 24
[shortcut]
from=-3
activation=linear

# 25
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 26
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 27
[shortcut]
from=-3
activation=linear

# 28
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 29
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 30
[shortcut]
from=-3
activation=linear

# 31
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 32
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 33
[shortcut]
from=-3
activation=linear

# 34
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

# 35
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 36
[shortcut]
from=-3
activation=linear

# +++ Downsample

# 37
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

# 38
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

######################

[convolutional] # 75
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional] # 76
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional] # 77
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional] # 78
batch_normalize=1 
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional] # 79
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

[convolutional] # 80
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
=leaky
activation
[conv-pre-yolo] # 81

[detection] # 82
mask = 6,7,8
anchors = 11,25  13,27  14,29  14,33  15,36  18,34  18,40  16,45  20,52
ignore_thresh = .7

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 61



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[conv-pre-yolo]

[detection]
mask = 3,4,5
anchors = 11,25  13,27  14,29  14,33  15,36  18,34  18,40  16,45  20,52
ignore_thresh = .7

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 36



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[conv-pre-yolo]

[detection]
mask = 0,1,2
anchors = 11,25  13,27  14,29  14,33  15,36  18,34  18,40  16,45  20,52
ignore_thresh = .7